# name: test/sql/copy/s3/version_id_pinning.test
# description: Test S3 version ID pinning: reads remain pinned to the original object version even after the file is overwritten.
# group: [s3]

require parquet

require httpfs

require-env S3_TEST_SERVER_AVAILABLE 1

require-env AWS_DEFAULT_REGION

require-env AWS_ACCESS_KEY_ID

require-env AWS_SECRET_ACCESS_KEY

require-env DUCKDB_S3_ENDPOINT

require-env DUCKDB_S3_USE_SSL

# override the default behaviour of skipping HTTP errors and connection failures: this test fails on connection issues
set ignore_error_messages

# disable external file cache to avoid interference from locally cached file content
statement ok
SET enable_external_file_cache=false;

# Create two tables with different row counts so we can distinguish them
statement ok
CREATE TABLE T1 AS SELECT i FROM range(100) tbl(i);

statement ok
CREATE TABLE T2 AS SELECT i FROM range(200) tbl(i);

# Write T1 to S3 (bucket must have versioning enabled)
statement ok
COPY T1 TO 's3://test-bucket-public/root-dir/version_pinning/test.parquet';

# Enable version pinning and the global metadata cache.
# The global metadata cache persists version_id across queries.
statement ok
SET s3_version_id_pinning=true;

statement ok
SET enable_http_metadata_cache=true;

# Read the file. This performs a HEAD request that captures version_id V1
# and stores it in the global metadata cache.
query I
SELECT COUNT(*) FROM 's3://test-bucket-public/root-dir/version_pinning/test.parquet';
----
100

# Disable the global metadata cache BEFORE overwriting.
# This way the COPY TO below erases from the per-context cache only,
# leaving the global cache entry (with V1's version_id) intact.
statement ok
SET enable_http_metadata_cache=false;

# Overwrite the file with T2 (200 rows), creating a new version V2.
# Because the global metadata cache is disabled, the write erases from
# the per-context cache, not the global cache.
statement ok
COPY T2 TO 's3://test-bucket-public/root-dir/version_pinning/test.parquet';

# Re-enable the global metadata cache. It still holds the V1 entry.
statement ok
SET enable_http_metadata_cache=true;

# Read the file again. The global cache provides the V1 version_id,
# so the GET request includes ?versionId=V1 and returns the original T1 data.
query I
SELECT COUNT(*) FROM 's3://test-bucket-public/root-dir/version_pinning/test.parquet';
----
100

# --- Clearing the version pin ---
# To read the latest version, we need to clear the cached version_id.
# Disabling the global metadata cache and version pinning achieves this:
# the per-context cache starts empty each query, and no version_id is captured.
statement ok
SET enable_http_metadata_cache=false;

statement ok
SET s3_version_id_pinning=false;

# Now the read gets the latest version (V2 = T2 data).
query I
SELECT COUNT(*) FROM 's3://test-bucket-public/root-dir/version_pinning/test.parquet';
----
200

# ============================================================
# Scenario 2: Cross-range consistency — pin on metadata read,
# overwrite, then read row-group data and verify no mixed content.
# ============================================================

# Create tables with a fixed value per version so we can detect any mixing.
# Use small ROW_GROUP_SIZE to force multiple GET-range requests when reading data.
statement ok
CREATE TABLE V1_DATA AS SELECT 1 AS val FROM range(10000);

statement ok
CREATE TABLE V2_DATA AS SELECT 2 AS val FROM range(10000);

# Write V1 with many small row groups → many range reads later
statement ok
COPY V1_DATA TO 's3://test-bucket-public/root-dir/version_pinning/range_test.parquet' (FORMAT PARQUET, ROW_GROUP_SIZE 1000);

# Enable version pinning + global metadata cache
statement ok
SET s3_version_id_pinning=true;

statement ok
SET enable_http_metadata_cache=true;

# Metadata-only read: COUNT(*) on parquet reads only the footer.
# This captures version_id V1 in the global metadata cache.
query I
SELECT COUNT(*) FROM 's3://test-bucket-public/root-dir/version_pinning/range_test.parquet';
----
10000

# Overwrite with V2 data while the global cache still holds V1.
# Disable global cache so the write doesn't erase the cached V1.
statement ok
SET enable_http_metadata_cache=false;

statement ok
COPY V2_DATA TO 's3://test-bucket-public/root-dir/version_pinning/range_test.parquet' (FORMAT PARQUET, ROW_GROUP_SIZE 1000);

statement ok
SET enable_http_metadata_cache=true;

# Read actual row-group data. The global cache supplies V1's version_id,
# so every GET-range request (one per row group) includes ?versionId=V1.
# All values must be 1 (from V1). If any range leaked V2, we'd see 2s.
query I
SELECT SUM(val) FROM 's3://test-bucket-public/root-dir/version_pinning/range_test.parquet';
----
10000

# Confirm zero rows from V2 — no mixed content across ranges
query I
SELECT COUNT(*) FROM 's3://test-bucket-public/root-dir/version_pinning/range_test.parquet' WHERE val != 1;
----
0

# --- Un-pin and verify we now see V2 ---
statement ok
SET enable_http_metadata_cache=false;

statement ok
SET s3_version_id_pinning=false;

query I
SELECT SUM(val) FROM 's3://test-bucket-public/root-dir/version_pinning/range_test.parquet';
----
20000

query I
SELECT COUNT(*) FROM 's3://test-bucket-public/root-dir/version_pinning/range_test.parquet' WHERE val != 2;
----
0
